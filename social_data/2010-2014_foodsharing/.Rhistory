#set number of random selections original classification rate should be based on:
ur.c.val=0
ur.sel=0
number=(1:nrow(xdata))
#get assignment of subjects to groups
gr=c()
subj.gr= table(contr_fac,test_fac)
subject=rownames(subj.gr)
for (i in 1:ncf.levels){
for (k in 1:ntf.levels){
if (subj.gr[i,k]>0) {gr=c(gr,colnames(subj.gr)[k])}
}
}
for (k in 1:n.sel){
#make random selection of same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ur.sel=ur.sel+sum((test_fac==pred)[sel==1])
ur.c.val= ur.c.val+ sum((test_fac==pred)[sel==0])
}
#save number of correctly classified calls in variable 'orig.res':
ur.sel= ur.sel/ n.sel
ur.c.val= ur.c.val/ n.sel
#set P-value to 1 (since original data should be treated as 1 permutation):
p.sel=1
p.c.val=1
all.corr=matrix(NA, nrow=nperm, ncol=2)
all.corr[1,1]=ur.sel
all.corr[1,2]=ur.c.val
if (length(gr)==ncf.levels){
for (k in 1:(nperm-1)){
#randomize subjects' assignments to groups:
r.gr=sample(gr,length(gr), replace=F)
for (i in 1:length(subject)){
test_fac[contr_fac==subject[i]]=r.gr[i]
}
#make random selection or same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ran.sel= sum((test_fac==pred)[sel==1])
ran.c.val= sum((test_fac==pred)[sel==0])
if (ran.sel>=ur.sel){p.sel = p.sel + 1}
if (ran.c.val>= ur.c.val){p.c.val= p.c.val + 1}
all.corr[k+1,1]=ran.sel
all.corr[k+1,2]=ran.c.val
}
what=c("N correctly assigned, original, selected", "P for selected", "N correctly assigned, original, cross-validated", "P for cross-validated", "N groups (levels of test factor)", "N subjects (levels of control factor)", "N cases total", "N cases selected per subject","N selected total", "N permutations","N random selections")
value=c(ur.sel,p.sel/nperm,ur.c.val,p.c.val/nperm,ntf.levels,ncf.levels,nrow(xdata),n.to.sel,n.to.sel*ncf.levels,nperm,n.sel)
result=data.frame(what,value)
}else{
result="at least one subject is member of two groups; no test done"
}
result
write.table(result,file=paste(JuliaPath,"tole3_lp1.txt"),sep="\t",row.names=F,col.names=T)
all.corr[,1]#comprises the number correctly classified selected objects for all
#permutations (with the first value being that for the original data)
all.corr[,2]#same for the cross-validated objects
hist(all.corr[,1])#shows the frequency distribution
###################################################################
#### 6 - late-post-intro Tole bats vs late-post-intro Las Pavas
xdata <- specan2 %>%
filter(group == "tole3" | group == "lp2")
test_fac <- as.factor(as.character(xdata$group))
contr_fac <- as.factor(as.character(xdata$individual))
variables <- paste(colnames(specan2)[3:ncol(specan2)], collapse = "+")
n.sel=100
nperm=1000
################################################################### copy-pasted code
if (is.factor(test_fac)==F) {test_fac=as.factor(test_fac)}
model=paste("lda(test_fac~",variables,", prior=pr_prob, subset=sel.index, data=xdata)",sep="")
f.table=as.data.frame(table(contr_fac))
ncf.levels=nrow(f.table)
ntf.levels=nrow(table(test_fac))
pr_prob=rep(1/ntf.levels, ntf.levels)#define prior probabilities to be equal for either of two groups
#get number of cases per subject (level of contrfac):
#get number of calls to select per subject (subject)
n.to.sel=min(f.table$Freq)
#set number of random selections original classification rate should be based on:
ur.c.val=0
ur.sel=0
number=(1:nrow(xdata))
#get assignment of subjects to groups
gr=c()
subj.gr= table(contr_fac,test_fac)
subject=rownames(subj.gr)
for (i in 1:ncf.levels){
for (k in 1:ntf.levels){
if (subj.gr[i,k]>0) {gr=c(gr,colnames(subj.gr)[k])}
}
}
for (k in 1:n.sel){
#make random selection of same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ur.sel=ur.sel+sum((test_fac==pred)[sel==1])
ur.c.val= ur.c.val+ sum((test_fac==pred)[sel==0])
}
#save number of correctly classified calls in variable 'orig.res':
ur.sel= ur.sel/ n.sel
ur.c.val= ur.c.val/ n.sel
#set P-value to 1 (since original data should be treated as 1 permutation):
p.sel=1
p.c.val=1
all.corr=matrix(NA, nrow=nperm, ncol=2)
all.corr[1,1]=ur.sel
all.corr[1,2]=ur.c.val
if (length(gr)==ncf.levels){
for (k in 1:(nperm-1)){
#randomize subjects' assignments to groups:
r.gr=sample(gr,length(gr), replace=F)
for (i in 1:length(subject)){
test_fac[contr_fac==subject[i]]=r.gr[i]
}
#make random selection or same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ran.sel= sum((test_fac==pred)[sel==1])
ran.c.val= sum((test_fac==pred)[sel==0])
if (ran.sel>=ur.sel){p.sel = p.sel + 1}
if (ran.c.val>= ur.c.val){p.c.val= p.c.val + 1}
all.corr[k+1,1]=ran.sel
all.corr[k+1,2]=ran.c.val
}
what=c("N correctly assigned, original, selected", "P for selected", "N correctly assigned, original, cross-validated", "P for cross-validated", "N groups (levels of test factor)", "N subjects (levels of control factor)", "N cases total", "N cases selected per subject","N selected total", "N permutations","N random selections")
value=c(ur.sel,p.sel/nperm,ur.c.val,p.c.val/nperm,ntf.levels,ncf.levels,nrow(xdata),n.to.sel,n.to.sel*ncf.levels,nperm,n.sel)
result=data.frame(what,value)
}else{
result="at least one subject is member of two groups; no test done"
}
result
write.table(result,file=paste(JuliaPath,"tole2_lp1.txt"),sep="\t",row.names=F,col.names=T)
all.corr[,1]#comprises the number correctly classified selected objects for all
#permutations (with the first value being that for the original data)
all.corr[,2]#same for the cross-validated objects
hist(all.corr[,1])#shows the frequency distribution
###################################################################
#### 3 - early-post-intro Tole bats vs early-post-intro Las Pavas
xdata <- specan2 %>%
filter(group == "tole2" | group == "lp1")
test_fac <- as.factor(as.character(xdata$group))
contr_fac <- as.factor(as.character(xdata$individual))
variables <- paste(colnames(specan2)[3:ncol(specan2)], collapse = "+")
n.sel=100
nperm=1000
################################################################### copy-pasted code
if (is.factor(test_fac)==F) {test_fac=as.factor(test_fac)}
model=paste("lda(test_fac~",variables,", prior=pr_prob, subset=sel.index, data=xdata)",sep="")
f.table=as.data.frame(table(contr_fac))
ncf.levels=nrow(f.table)
ntf.levels=nrow(table(test_fac))
pr_prob=rep(1/ntf.levels, ntf.levels)#define prior probabilities to be equal for either of two groups
#get number of cases per subject (level of contrfac):
#get number of calls to select per subject (subject)
n.to.sel=min(f.table$Freq)
#set number of random selections original classification rate should be based on:
ur.c.val=0
ur.sel=0
number=(1:nrow(xdata))
#get assignment of subjects to groups
gr=c()
subj.gr= table(contr_fac,test_fac)
subject=rownames(subj.gr)
for (i in 1:ncf.levels){
for (k in 1:ntf.levels){
if (subj.gr[i,k]>0) {gr=c(gr,colnames(subj.gr)[k])}
}
}
for (k in 1:n.sel){
#make random selection of same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ur.sel=ur.sel+sum((test_fac==pred)[sel==1])
ur.c.val= ur.c.val+ sum((test_fac==pred)[sel==0])
}
#save number of correctly classified calls in variable 'orig.res':
ur.sel= ur.sel/ n.sel
ur.c.val= ur.c.val/ n.sel
#set P-value to 1 (since original data should be treated as 1 permutation):
p.sel=1
p.c.val=1
all.corr=matrix(NA, nrow=nperm, ncol=2)
all.corr[1,1]=ur.sel
all.corr[1,2]=ur.c.val
if (length(gr)==ncf.levels){
for (k in 1:(nperm-1)){
#randomize subjects' assignments to groups:
r.gr=sample(gr,length(gr), replace=F)
for (i in 1:length(subject)){
test_fac[contr_fac==subject[i]]=r.gr[i]
}
#make random selection or same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ran.sel= sum((test_fac==pred)[sel==1])
ran.c.val= sum((test_fac==pred)[sel==0])
if (ran.sel>=ur.sel){p.sel = p.sel + 1}
if (ran.c.val>= ur.c.val){p.c.val= p.c.val + 1}
all.corr[k+1,1]=ran.sel
all.corr[k+1,2]=ran.c.val
}
what=c("N correctly assigned, original, selected", "P for selected", "N correctly assigned, original, cross-validated", "P for cross-validated", "N groups (levels of test factor)", "N subjects (levels of control factor)", "N cases total", "N cases selected per subject","N selected total", "N permutations","N random selections")
value=c(ur.sel,p.sel/nperm,ur.c.val,p.c.val/nperm,ntf.levels,ncf.levels,nrow(xdata),n.to.sel,n.to.sel*ncf.levels,nperm,n.sel)
result=data.frame(what,value)
}else{
result="at least one subject is member of two groups; no test done"
}
result
write.table(result,file=paste(JuliaPath,"tole2_lp1.txt"),sep="\t",row.names=F,col.names=T)
#### 6 - late-post-intro Tole bats vs late-post-intro Las Pavas
xdata <- specan2 %>%
filter(group == "tole3" | group == "lp2")
test_fac <- as.factor(as.character(xdata$group))
contr_fac <- as.factor(as.character(xdata$individual))
variables <- paste(colnames(specan2)[3:ncol(specan2)], collapse = "+")
n.sel=100
nperm=1000
################################################################### copy-pasted code
if (is.factor(test_fac)==F) {test_fac=as.factor(test_fac)}
model=paste("lda(test_fac~",variables,", prior=pr_prob, subset=sel.index, data=xdata)",sep="")
f.table=as.data.frame(table(contr_fac))
ncf.levels=nrow(f.table)
ntf.levels=nrow(table(test_fac))
pr_prob=rep(1/ntf.levels, ntf.levels)#define prior probabilities to be equal for either of two groups
#get number of cases per subject (level of contrfac):
#get number of calls to select per subject (subject)
n.to.sel=min(f.table$Freq)
#set number of random selections original classification rate should be based on:
ur.c.val=0
ur.sel=0
number=(1:nrow(xdata))
#get assignment of subjects to groups
gr=c()
subj.gr= table(contr_fac,test_fac)
subject=rownames(subj.gr)
for (i in 1:ncf.levels){
for (k in 1:ntf.levels){
if (subj.gr[i,k]>0) {gr=c(gr,colnames(subj.gr)[k])}
}
}
for (k in 1:n.sel){
#make random selection of same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ur.sel=ur.sel+sum((test_fac==pred)[sel==1])
ur.c.val= ur.c.val+ sum((test_fac==pred)[sel==0])
}
#save number of correctly classified calls in variable 'orig.res':
ur.sel= ur.sel/ n.sel
ur.c.val= ur.c.val/ n.sel
#set P-value to 1 (since original data should be treated as 1 permutation):
p.sel=1
p.c.val=1
all.corr=matrix(NA, nrow=nperm, ncol=2)
all.corr[1,1]=ur.sel
all.corr[1,2]=ur.c.val
if (length(gr)==ncf.levels){
for (k in 1:(nperm-1)){
#randomize subjects' assignments to groups:
r.gr=sample(gr,length(gr), replace=F)
for (i in 1:length(subject)){
test_fac[contr_fac==subject[i]]=r.gr[i]
}
#make random selection or same number of cases per subject
sel=rep(NA,nrow(xdata))#create var. for the random selection to be indicated
for (i in 1:ncf.levels){
sel[contr_fac==subject[i]] =sample(c(rep(1, n.to.sel), rep(0,f.table[i,2]-n.to.sel)), f.table[i,2],replace=F)
}
sel.index= number[sel==1]
#do a DFA and store results in 'res':
res=eval(parse(text=model))
#get predictions and store them in 'pred':
pred=predict(res,xdata,prior=pr_prob)$class
ran.sel= sum((test_fac==pred)[sel==1])
ran.c.val= sum((test_fac==pred)[sel==0])
if (ran.sel>=ur.sel){p.sel = p.sel + 1}
if (ran.c.val>= ur.c.val){p.c.val= p.c.val + 1}
all.corr[k+1,1]=ran.sel
all.corr[k+1,2]=ran.c.val
}
what=c("N correctly assigned, original, selected", "P for selected", "N correctly assigned, original, cross-validated", "P for cross-validated", "N groups (levels of test factor)", "N subjects (levels of control factor)", "N cases total", "N cases selected per subject","N selected total", "N permutations","N random selections")
value=c(ur.sel,p.sel/nperm,ur.c.val,p.c.val/nperm,ntf.levels,ncf.levels,nrow(xdata),n.to.sel,n.to.sel*ncf.levels,nperm,n.sel)
result=data.frame(what,value)
}else{
result="at least one subject is member of two groups; no test done"
}
result
write.table(result,file=paste(JuliaPath,"tole3_lp2.txt"),sep="\t",row.names=F,col.names=T)
readRDS("/Users/jkvrtilek/Desktop/OSU/PhD/Calls/selectionTables2021-10-01.RDS")
library(diffr)
diffr("/Users/jkvrtilek/Downloads/spectro_analysis.R","/Users/jkvrtilek/Downloads/spectro_analysis_testing.R")
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(tidyverse)
library(warbleR)
library(soundgen)
# read in data
JuliaPaths <- c("/Users/jkvrtilek/Desktop/OSU/PhD/Calls/selectionTables2022-03-21.RDS", "/Volumes/call_drive2")
GerryPaths <- ""
GracePaths <- ""
selAll <- readRDS(JuliaPaths[1])
# add columns for bat, date, year, month, and day
selAll <- selAll %>%
separate(col = sound.files, into = c("date", "bat", NA), sep = "_", remove = FALSE) %>%
separate(col = date, into = c("year", "month", "day"), sep = "-", remove = FALSE)
knitr::opts_chunk$set(echo = TRUE)
# load packages
library(tidyverse)
library(warbleR)
library(soundgen)
# read in data
JuliaPaths <- c("/Users/jkvrtilek/Desktop/OSU/PhD/Calls/selectionTables2022-03-21.RDS", "/Volumes/call_drive2")
GerryPaths <- ""
GracePaths <- ""
selAll <- readRDS(JuliaPaths[1])
# add columns for bat, date, year, month, and day
selAll <- selAll %>%
separate(col = sound.files, into = c("date", "bat", NA), sep = "_", remove = FALSE) %>%
separate(col = date, into = c("year", "month", "day"), sep = "-", remove = FALSE)
# read in list of file paths
metadata <- read_csv("/Users/jkvrtilek/Desktop/OSU/PhD/Calls/Selection/whole_recordings_renamed_metadata.csv")
# add file paths to selection table
selAll <- selAll %>%
left_join(metadata, by = c("sound.files" = "new_sound_file_nm")) %>%
select(c(1:11,18:21))
# change file paths for appropriate computer
selAll$new_sound_file_dir <- str_replace(selAll$new_sound_file_dir, "D:", JuliaPaths[2])
selNA <- selAll %>%
filter(is.na(selection_length))
selNoNA <- selAll %>%
filter(!is.na(selection_length))
rowsperfile <- unique(selNA$sound.files)
print(paste("There are", length(rowsperfile), "WAVs with missing data."))
if(nrow(selNA) == length(rowsperfile)) {
print("There is only one 'missing' selection for each WAV file that is missing data.")
} else {
print("Check on me!")
}
missingFiles <- unique(selNA$sound.files)
selWithMissing <- selAll %>%
filter(sound.files %in% missingFiles)
if(nrow(selNA) == nrow(selWithMissing)) {
print("They do not! Hooray!")
} else {
print("Check on me!")
}
sel2019 <- selAll %>%
filter(year == 2019)
selNA %>%
group_by(date.x) %>%
summarize(count = n())
sel2019 %>%
group_by(date.x) %>%
summarize(count = n())
View(selAll)
# make histogram to see where to place cutoff between echolocation and contact calls
selCutoff <- selAll %>%
filter(selection_length >= .001) %>%
filter(selection_length <= .005)
hist(selCutoff$selection_length, breaks = 1000)
selByBat <- selAll %>%
group_by(bat) %>%
summarize(count = n()) %>%
arrange(count)
print(paste("We tried to record", nrow(selByBat), "different bats."))
print(paste("We have recordings from", nrow(selByBat), "different bats."))
print(paste("The bat with the fewest calls is", selByBat$bat[1], ", who called", selByBat$count[1], "times."))
print(paste("The bat with the most calls is", selByBat$bat[nrow(selByBat)], ", who called", selByBat$count[nrow(selByBat)], "times."))
selByDate <- selAll %>%
group_by(bat, date.x) %>%
summarise(count = n()) %>%
arrange(count)
print(paste("There are", nrow(selByDate), "total recording sessions."))
print(paste("The bat with the fewest calls in a day is", selByDate$bat[1], ", who called", selByDate$count[1], "times."))
print(paste("The bat with the most calls in a day is", selByDate$bat[nrow(selByDate)], ", who called", selByDate$count[nrow(selByDate)], "times."))
selAll %>%
filter(start < 1) %>%
mutate(year = substr(date, 1, 4)) %>%
ggplot(aes(x = start)) +
facet_wrap(~ year, scales = "free_y", ncol = 1) +
geom_histogram()
View(selAll)
selAll %>%
filter(start < 1) %>%
ggplot(aes(x = start)) +
facet_wrap(~ year, scales = "free_y", ncol = 1) +
geom_histogram()
# Julia Vrtilek
# March 2022
# script to clean spectro_analysis output
# load packages
library(tidyverse)
# set file paths
JuliaPath <- "/Users/jkvrtilek/Desktop/OSU/PhD/Calls/"
GerryPath <- ""
# read in data
d <- readRDS(paste(JuliaPath, "giantspecan.RDS", sep = ""))
# convert duration to milliseconds
d$duration <- d$duration*1000
# make histograms of all measures
for (col in 3:ncol(d)) {
hist(d[,col], main = colnames(d[col]))
}
# count impossible measures
range(d$duration)
tooshort <- sum(d$duration < 3)
toolong <- sum(d$duration > 50)
range(d$peakf)
toolow <- sum(d$peakf < 10)
toohigh <- sum(d$peakf > 40)
# filter out impossible data
d2 <- d %>%
filter(duration > 3) %>%
filter(duration < 50) %>%
filter(peakf > 10) %>%
filter(peakf < 40)
# lots of overlap in the impossible data... that's good, right?
# make histograms of all measures
for (col in 3:ncol(d2)) {
hist(d2[,col], main = colnames(d2[col]))
}
d <- readRDS("/Users/jkvrtilek/Desktop/OSU/PhD/Calls/DFA_loadings.RDS")
View(d)
readRDS("/Users/jkvrtilek/Desktop/OSU/PhD/Calls/DFA_loadings_goodbadmeh.RDS")
# make histograms of all measures
for (col in 3:ncol(d2)) {
hist(log(d2[,col]+1), main = colnames(d2[col]))
}
x <- readRDS("/Users/jkvrtilek/Downloads/count_upload.RDS")
setwd("/Users/jkvrtilek/Downloads")
readRDS(count_upload.RDS)
getwd()
readRDS("count_upload.RDS")
# clear workspace
rm(list=ls())
# load packages
library(tidyverse)
# set working directory
setwd("/Users/jkvrtilek/Desktop/OSU/PhD/GitHub/call-convergence/social_data/2010-2014_foodsharing")
# get data from University of Maryland (UMD) colony (from unpublished oxytocin pilot study)
umd <-
read.csv("2013_oxytocin_social_data.csv") %>%
mutate(subject= paste0("bat",subject)) %>%
mutate(donor= paste0("bat",donor)) %>%
# numbers are count of minutes that have at least 5 sec of behavior (multiplying by 60 will overestimate actual seconds)
# convert minutes to seconds assuming 40 s of sharing per minute with at least 5 s of food sharing
# this adjustment creates matching food transfer rates based on all other data (see linear model below)
mutate(grooming = (grooming*40), sharing = (sharing*40)) %>%
as_tibble()
# check that sharing per trial causes mass gain to a degree that matches past work
t <-
umd %>%
group_by(trial) %>%
summarize(mass.gain= mean(trial.mass.gain.subject, na.rm=T), sharing= sum(sharing, na.rm=T)) %>%
mutate(sharing.min= sharing/60, mass.gain.mg= mass.gain*1000)
# plot looks similar to other work (see Figure S1 in Carter & Wilkinson 2015 Proc B)
t %>%
ggplot(aes(x=sharing, y=mass.gain))+
geom_point(size=2)+
geom_smooth(method= "lm")+
xlab("mouthlicking (seconds)")+
ylab("weight gain (grams)")
library(diffr)
diffr("/Users/jkvrtilek/Desktop/OSU/PhD/GitHub/call-convergence/social_data/2010-2014_foodsharing/compile_2014_foodsharing_data03.R","/Users/jkvrtilek/Downloads/compile_2014_foodsharing_data06.R")
